name: TrendRadar scheduled run (Beijing 08:00/12:00/18:00)

on:
  schedule:
    # Times are in UTC. Beijing = UTC+8, so 08:00/12:00/18:00 BJT => 00:00/04:00/10:00 UTC
    - cron: '0 0 * * *'
    - cron: '0 4 * * *'
    - cron: '0 10 * * *'
  workflow_dispatch: {}

jobs:
  crawl-and-publish:
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: 1
      DATABASE_URL: sqlite:///./src/data.db
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run collectors and postprocess to generate static HTML
        run: |
          export PYTHONPATH=$(pwd)
          mkdir -p output
          # Initialize DB and run collectors (persist results)
          python3 scripts/run_collectors.py || true
          # generate timestamped output file and an overall index file
          TIMESTAMP=$(date -u +"%Y-%m-%d_%H%M")
          python3 scripts/dedup_anchors.py --in scripts/postprocess_anchors.json --threshold 0.90 --json-out output/postprocess_deduped_${TIMESTAMP}.json --html-out output/postprocess_deduped_${TIMESTAMP}.report.html || true
          cp output/postprocess_deduped_${TIMESTAMP}.report.html output/index.html || true

      - name: Publish output/ to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./output
          publish_branch: gh-pages
          keep_files: false
